{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, glob, yaml\n",
    "sys.path.append('../toolbox/')\n",
    "sys.path.append('../weld')\n",
    "from lambda_calc import *\n",
    "from multi_robot import *\n",
    "from dx200_motion_program_exec_client import *\n",
    "from WeldSend import *\n",
    "from RobotRaconteur.Client import *\n",
    "from weldRRSensor import *\n",
    "from motoman_def import *\n",
    "from flir_toolbox import *\n",
    "import weld_dh2v\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def get_trailing_number(s):\n",
    "    m = re.search(r'\\d+$', s)\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "layer = 597\n",
    "x=0\n",
    "\n",
    "dataset='bent_tube/'\n",
    "sliced_alg='slice_ER_4043_dense/'\n",
    "data_dir='../data/'+dataset+sliced_alg\n",
    "\n",
    "def flame_detection_aluminum(raw_img,threshold=1.0e4,area_threshold=4,percentage_threshold=0.8):\n",
    "    ###flame detection by raw counts thresholding and connected components labeling\n",
    "    #centroids: x,y\n",
    "    #bbox: x,y,w,h\n",
    "    ###adaptively increase the threshold to 60% of the maximum pixel value\n",
    "    threshold=max(threshold,percentage_threshold*np.max(raw_img))\n",
    "    thresholded_img=(raw_img>threshold).astype(np.uint8)\n",
    "\n",
    "    nb_components, labels, stats, centroids = cv2.connectedComponentsWithStats(thresholded_img, connectivity=4)\n",
    "    \n",
    "    valid_indices=np.where(stats[:, cv2.CC_STAT_AREA] > area_threshold)[0][1:]  ###threshold connected area\n",
    "    if len(valid_indices)==0:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    average_pixel_values = [np.mean(raw_img[labels == label]) for label in valid_indices]   ###sorting\n",
    "    valid_index=valid_indices[np.argmax(average_pixel_values)]      ###get the area with largest average brightness value\n",
    "\n",
    "    # Extract the centroid and bounding box of the largest component\n",
    "    centroid = centroids[valid_index]\n",
    "    bbox = stats[valid_index, :-1]\n",
    "\n",
    "    return centroid, bbox\n",
    "\n",
    "robot=robot_obj('MA2010_A0',def_path='../config/MA2010_A0_robot_default_config.yml',tool_file_path='../config/torch.csv',\\\n",
    "\tpulse2deg_file_path='../config/MA2010_A0_pulse2deg_real.csv',d=15)\n",
    "robot2=robot_obj('MA1440_A0',def_path='../config/MA1440_A0_robot_default_config.yml',tool_file_path='../config/flir.csv',\\\n",
    "\tpulse2deg_file_path='../config/MA1440_A0_pulse2deg_real.csv',base_transformation_file='../config/MA1440_pose.csv')\n",
    "positioner=positioner_obj('D500B',def_path='../config/D500B_robot_extended_config.yml',tool_file_path='../config/positioner_tcp.csv',\\\n",
    "\tpulse2deg_file_path='../config/D500B_pulse2deg_real.csv',base_transformation_file='../config/D500B_pose.csv')\n",
    "\n",
    "config_dir='../config/'\n",
    "flir_intrinsic=yaml.load(open(config_dir+'FLIR_A320.yaml'), Loader=yaml.FullLoader)\n",
    "\n",
    "layer = 1\n",
    "save_path = f'../../recorded_data/ER4043_bent_tube_2024_07_18_13_37_40/layer_{layer}/'\n",
    "with open(save_path+'ir_recording.pickle', 'rb') as file:\n",
    "        ir_recording = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "899\n"
     ]
    }
   ],
   "source": [
    "flame_3d=[]\n",
    "job_no = []\n",
    "ir_ts=np.loadtxt(save_path+'ir_stamps.csv', delimiter=',')\n",
    "if len(ir_ts)>0:\n",
    "    joint_angle=np.loadtxt(save_path+'weld_js_exe.csv', delimiter=',')\n",
    "\n",
    "    timeslot=[ir_ts[0]-ir_ts[0], ir_ts[-1]-ir_ts[0]]\n",
    "    duration=np.mean(np.diff(timeslot))\n",
    "\n",
    "\n",
    "    for start_time in timeslot[:-1]:\n",
    "        \n",
    "        start_idx=np.argmin(np.abs(ir_ts-ir_ts[0]-start_time))\n",
    "        end_idx=np.argmin(np.abs(ir_ts-ir_ts[0]-start_time-duration))\n",
    "        print(start_idx)\n",
    "        print(end_idx)\n",
    "\n",
    "        #find all pixel regions to record from flame detection\n",
    "        for i in range(start_idx,end_idx):\n",
    "            \n",
    "            ir_image = ir_recording[i]\n",
    "            try:\n",
    "                centroid, bbox=flame_detection_aluminum(ir_image, percentage_threshold=0.8)\n",
    "            except ValueError:\n",
    "                centroid = None\n",
    "            if centroid is not None:\n",
    "                #find spatial vector ray from camera sensor\n",
    "                vector=np.array([(centroid[0]-flir_intrinsic['c0'])/flir_intrinsic['fsx'],(centroid[1]-flir_intrinsic['r0'])/flir_intrinsic['fsy'],1])\n",
    "                vector=vector/np.linalg.norm(vector)\n",
    "                #find index closest in time of joint_angle\n",
    "                joint_idx=np.argmin(np.abs(ir_ts[i]-joint_angle[:,0]))\n",
    "                robot2_pose_world=robot2.fwd(joint_angle[joint_idx][8:-2],world=True)\n",
    "                p2=robot2_pose_world.p\n",
    "                v2=robot2_pose_world.R@vector\n",
    "                robot1_pose=robot.fwd(joint_angle[joint_idx][2:8])\n",
    "                p1=robot1_pose.p\n",
    "                v1=robot1_pose.R[:,2]\n",
    "                positioner_pose=positioner.fwd(joint_angle[joint_idx][-2:], world=True)\n",
    "\n",
    "                #find intersection point\n",
    "                intersection=line_intersect(p1,v1,p2,v2)\n",
    "                intersection = positioner_pose.R@(intersection-(positioner_pose.p))# +np.array([0,0,10])))\n",
    "\n",
    "                flame_3d.append(intersection)\n",
    "                job_no.append(int(joint_angle[joint_idx][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(job_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
